1. 현재 상황 요약
데이터는 GPT로 생성된 문장만 확보

지도교수님은 다양한 AI 모델(Gemini, Claude, etc.)도 포함하길 원함

그러나 공개된 생성 텍스트 데이터는 부족

그래서 AI 모델 의존 없이, **“문장 자체의 통계적 특성”**을 활용하자 → Good idea

2. “통계적 특성” 기반 감지란?
AI가 쓴 글은 사람과 다르게 다음과 같은 특성이 있어요:

특성 항목	사람	AI
Perplexity	높음	낮음
Burstiness	큼	작음
단어 다양성 (Type-Token Ratio)	높음	낮음
길이/어휘 패턴의 균일성	다양함	일정함
문장 구조 반복	적음	많음

이런 **텍스트의 "자연스러움"이나 "예측 불가성"**이 사람과 AI의 주요 차이점이에요.
특히 GPT 계열 모델은 예측 가능한 패턴을 많이 생성하죠.

3. 가능한 기술 접근
아래와 같은 통계 기반 피처들을 추출해서 모델에 넣으면, GPT뿐 아니라 향후 Gemini/Claude도 구별할 수 있는 범용 AI 감지기의 기반이 돼요.

(1) Feature Engineering
Perplexity 점수: GPT-2/3 기반 언어 모델로 계산

Burstiness (문장 길이/형태의 다양성): 평균, 표준편차

n-gram 반복 빈도: 너무 반복되는 구문 수

Type-Token Ratio (어휘 다양성)

형태소 기반 품사 분포: 너무 명사 위주 or 부사 없이 간결한 패턴

문장 구조/구문 분석 결과: 너무 일관된 문장 구조 (SVO 반복 등)

(2) ML 모델 적용
위 피처들을 기반으로 RandomForest, SVM, 또는 간단한 MLP 등 적용 가능

학습은 GPT 텍스트 vs 인간 텍스트로 하되,
**“특정 모델 기반이 아닌 패턴”**을 학습하게 됨 → 일반화 가능성 증가

4. 장점
모델 중립적 감지기 → Gemini, Claude, GPT 등 어떤 생성기에도 확장 가능

직접 만든 생성 텍스트 외에도, 사람 글(뉴스, 블로그, 위키 등)만 있으면 학습 가능

졸업작품으로는 기술적 깊이 + 현실성 + 학술적 의의 모두 챙길 수 있음

5. 실제로 이런 연구도 있음
DetectGPT (2023): Perplexity 기반 감지

GLTR: GPT-2 기반으로 단어 예측 확률 시각화

위처럼 언어 모델이 예측한 단어들의 확률 분포로 AI 여부 판단하는 연구들이 실제로 있어요.
이 논문이나 툴을 참고해서 구현하거나 확장하는 것도 훌륭한 방법이에요.

결론
“특정 AI 모델에 의존하지 않고, 통계적 특징만으로 AI 텍스트를 구분하는 방법”은 분명히 가능하고, 졸업 작품으로도 아주 훌륭한 방향이에요.

원한다면:

사용 가능한 오픈소스 데이터 추천

Perplexity 계산 코드

통계 피처 추출 방법

전체 아키텍처 구성

같은 것도 같이 짜볼 수 있어요. 지금 가진 샘플 데이터나 코드 있어? 한 번 같이 볼까?